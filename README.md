## ğŸ§‘â€ğŸ“ About Me
ğŸ“ Iâ€™m a third-year Ph.D. student in School of Computer Science and Engineering at **South China University of Technology (SCUT)**, advised by Prof. Qianli Ma. Previously, I obtained my bachelor's degree from this institute with the qualification for postgraduate recommendation and later applied for a direct Ph.D. program in my first year of graduate studies.

ğŸ”¬ My research focuses on  **LLM Alignment**, **Post Training** and **Preference Optimization**.

ğŸ“„ [Google Scholar](https://scholar.google.com/citations?user=WsTNqM8AAAAJ) | [ORCID](https://orcid.org/0000-0002-9704-1479)

---

## ğŸ“š Research Internship
### **Microsoft AI**
**July 2024 - Now  |  Research Intern**<br>
The research focuses on the methods for data flywheels for code LLMs. Current methods typically rely on off-the-shelf datasets and data augmentation from proprietary LLMs. We propose WarriorCoder, a novel paradigm where the target model learns from expert battles to address these limitations.



### **é€šä¹‰å®éªŒå®¤**
**July 2023 - July 2024  |  Research Intern**<br>
The research focuses on hallucinations in LLMs and methods for resolving the problem. We propose Contrastive Preference Optimization (CPO) â€” a method to improve the modelâ€™s faithfulness to the context during the generation process without the need for pairwise annotations. Furthermore, we explore the model's "selective" faithfulness to the context and propose Backtracking Correction (BC) â€” a reinforcement learning framework that does not require additional data annotations.

---

## ğŸ“ Publications
ğŸ“Œ **[WarriorCoder: Learning from Expert Battles to Augment Code Large Language Models](https://arxiv.org/abs/2412.17395)**<br>
âœï¸ **Huawen Feng**, Pu Zhao, Qingfeng Sun, Can Xu, Fangkai Yang, Lu Wang, Qianli Ma, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang<br>
ğŸ›ï¸ **Preprint** 

ğŸ“Œ **[Training Large Language Models for Retrieval-Augmented Question Answering through Backtracking Correction](https://openreview.net/forum?id=IOg47mg74i)**<br>
âœï¸ **Huawen Feng**, Zekun Yao,Â Junhao Zheng,Â Qianli Ma<br>
ğŸ›ï¸ **2025 ICLR** 

ğŸ“Œ **[Improving Factual Consistency of News Summarization by Contrastive Preference Optimization](https://aclanthology.org/2024.findings-emnlp.648/)**<br> 
âœï¸ **Huawen Feng**,Â Yan Fan,Â Xiong Liu,Â Ting-En Lin,Â Zekun Yao,Â Yuchuan Wu,Â Fei Huang,Â Yongbin Li,Â Qianli Ma<br>
ğŸ›ï¸ **2024 EMNLP (Findings)** 

ğŸ“Œ **[Well Begun Is Half Done: An Implicitly Augmented Generative Framework with Distribution Modification for Hierarchical Text Classification](https://aclanthology.org/2024.lrec-main.1515/)**<br> 
âœï¸ **Huawen Feng**, Jingsong Yan, Junlong Liu, Junhao Zheng, Qianli Ma<br>
ğŸ›ï¸ **2024 COLING** 

ğŸ“Œ **[Perturbation-Based Self-Supervised Attention for Attention Bias in Text Classification](https://ieeexplore.ieee.org/document/10209221/)**<br> 
âœï¸ **Huawen Feng**, Zhenxi Lin, Qianli Ma<br>
ğŸ›ï¸ **IEEE/ACM Transactions on Audio, Speech, and Language Processing** 

ğŸ“Œ **[Joint Constrained Learning with Boundary-adjusting for Emotion-Cause Pair Extraction](https://aclanthology.org/2023.acl-long.62/)**<br> 
âœï¸ **Huawen Feng**, Junlong Liu, Junhao Zheng, Haibin Chen, Xichen Shang, Qianli Ma<br>
ğŸ›ï¸ **2023 ACL** 

ğŸ“Œ **[It's Better to Teach Fishing than Giving a Fish: An Auto-Augmented Structure-aware Generative Model for Metaphor Detection](https://aclanthology.org/2023.acl-long.62/)**<br> 
âœï¸ **Huawen Feng**, Qianli Ma<br>
ğŸ›ï¸ **2022 EMNLP (Findings)** 

ğŸ“Œ **[More Papers](https://scholar.google.com/citations?user=WsTNqM8AAAAJ)**

---

## ğŸ“¬ Contact Information  
âœ‰ï¸ Email: [541119578@qq.com]

